{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eed980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OPENAI_API_KEY found  and the API key is: sk-proj-\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(f\"âœ… OPENAI_API_KEY found  and the API key is: {os.getenv(\"OPENAI_API_KEY\")[:8]}\")\n",
    "else:\n",
    "    print(\"âŒ OPENAI_API_KEY not found\")\n",
    "    print(\"   Create a .env file with: OPENAI_API_KEY=your-key-here\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87e92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826c8a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF: ../sample_data/notes.txt\n",
      "â³ This may take a moment...\n",
      "\n",
      "ðŸ“„ Original document: 8567 characters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_path = \"../sample_data/notes.txt\"\n",
    "if Path(text_path).exists():\n",
    "    print(f\"Loading PDF: {text_path}\")\n",
    "    print(\"â³ This may take a moment...\\n\")\n",
    "    try:\n",
    "        loader = TextLoader(text_path)\n",
    "        documents = loader.load()\n",
    "        print(f\"ðŸ“„ Original document: {len(documents[0].page_content)} characters\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {text_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edcb922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ Split into 12 chunks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,        # Maximum chunk size in characters\n",
    "        chunk_overlap=200,      # Overlap between chunks\n",
    "        length_function=len,    # How to measure length\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # Try these in order\n",
    "    )\n",
    "    \n",
    "    # Split the document\n",
    "chunks = splitter.split_documents(documents)\n",
    "    \n",
    "print(f\"âœ‚ï¸ Split into {len(chunks)} chunks\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4317065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Chunk 1 (991 chars):\n",
      "======================================================================\n",
      "LANGCHAIN STUDY NOTES - RAG IMPLEMENTATION\n",
      "==========================================\n",
      "\n",
      "Date: January 15, 2025\n",
      "Topic: Retrieval-Augmented Generation with LangChain 1.0+\n",
      "\n",
      "\n",
      "CORE CONCEPTS\n",
      "-------------\n",
      "\n",
      "1. Document Object Structure\n",
      "   - page_content: The actual text content\n",
      "   - metadata: Dictionary wit...\n",
      "\n",
      "======================================================================\n",
      "Chunk 2 (801 chars):\n",
      "======================================================================\n",
      "TEXT SPLITTING STRATEGIES\n",
      "--------------------------\n",
      "\n",
      "RecursiveCharacterTextSplitter (RECOMMENDED)\n",
      "- Tries to split on semantic boundaries\n",
      "- Order: double newline â†’ newline â†’ period â†’ space â†’ character\n",
      "- Best for general text and documentation\n",
      "- Configuration: chunk_size=1000, chunk_overlap=200\n",
      "\n",
      "Cha...\n",
      "\n",
      "======================================================================\n",
      "Chunk 3 (864 chars):\n",
      "======================================================================\n",
      "TokenTextSplitter\n",
      "- Splits based on token count, not characters\n",
      "- More accurate for LLM context window limits\n",
      "- Uses tiktoken for OpenAI models\n",
      "\n",
      "\n",
      "CHUNK SIZE GUIDELINES\n",
      "----------------------\n",
      "\n",
      "Content Type          | Chunk Size | Overlap | Notes\n",
      "----------------------|------------|---------|---------...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks[:3], 1):\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Chunk {i} ({len(chunk.page_content)} chars):\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(chunk.page_content[:300] + \"...\" if len(chunk.page_content) > 300 else chunk.page_content)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1d5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
